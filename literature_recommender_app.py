import streamlit as st
import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from sentence_transformers import SentenceTransformer, util
import torch

# ---- êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ---- #
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_dict(
    st.secrets["gcp_service_account"], scope
)
client = gspread.authorize(creds)
sheet = client.open("ap jeongbo alzar takkarsenn").sheet1

# ---- Streamlit ì›¹ UI ---- #
st.set_page_config(page_title="ğŸ“š ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ", page_icon="ğŸ“š", layout="wide")
st.markdown("""
<style>
    .stButton>button { background-color: #6c63ff; color: white; }
    .stTextInput>div>input, .stTextArea>div>textarea { background-color: #fff; }
</style>""", unsafe_allow_html=True)
st.title("ğŸ“š AI ê¸°ë°˜ ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ")

# ë°ì´í„° ì…ë ¥ í¼
with st.form("book_form"):
    title = st.text_input("ì‘í’ˆëª…*")
    author = st.text_input("ì €ì*")
    country = st.text_input("êµ­ê°€")
    period = st.text_input("ì‹œëŒ€")
    genre = st.text_input("ì¥ë¥´*")
    emotion = st.text_input("ê°ì •* (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°ì • ì…ë ¥)")
    opinion = st.text_area("í‰ê°€*", height=120)
    user = st.text_input("ë‹‰ë„¤ì„ (ì„ íƒ)")
    submit = st.form_submit_button("ğŸ“¤ ì œì¶œ")
    if submit:
        if title and author and opinion:
            sheet.append_row([title, author, country, period, genre, emotion, opinion, user])
            st.success("âœ… ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("âš  ì‘í’ˆëª…, ì €ì, í‰ê°€ë¥¼ ê¼­ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ìµœê·¼ ê¸°ë¡ ë³´ê¸°
st.header("ğŸ“„ ìµœê·¼ ì…ë ¥ëœ ì‘í’ˆ")
try:
    df_recent = pd.DataFrame(sheet.get_all_records())
    st.dataframe(df_recent[::-1], use_container_width=True) if not df_recent.empty else st.info("ì•„ì§ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
except:
    st.error("ì‹œíŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨!")

# AI ì¶”ì²œ
st.header("ğŸ” ë„ì„œ ì¶”ì²œ ë°›ê¸°")
@st.cache_data(ttl=600)
def load_data():
    df = pd.DataFrame(sheet.get_all_records())
    if df.empty: return df
    df.columns = [c.strip() for c in df.columns]
    df.fillna("", inplace=True)
    df["ê°ì •"] = df["ê°ì •"].astype(str).str.replace(",", " ")
    df["combined_text"] = (
        "ì¥ë¥´: " + df["ì¥ë¥´"] +
        " ê°ì •: " + df["ê°ì •"] +
        " í‰ê°€: " + df["í‰ê°€"]
    )
    return df

@st.cache_resource
def load_model():
    return SentenceTransformer("jhgan/ko-sroberta-multitask")

df = load_data()
model = load_model()

query = st.text_input("ì¶”ì²œ í‚¤ì›Œë“œë‚˜ ê°ì •ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ ë¶„ë¦¬ ê°€ëŠ¥)")

if query:
    if df.empty:
        st.warning("âš  ë¨¼ì € ì‘í’ˆì„ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        query_list = [q.strip() for q in query.split(",")]
        query_embs = model.encode(query_list, convert_to_tensor=True)
        avg_query_emb = torch.mean(query_embs, dim=0, keepdim=True)

        doc_embs = model.encode(df["combined_text"].tolist(), convert_to_tensor=True)
        cos_scores = util.pytorch_cos_sim(avg_query_emb, doc_embs)[0]
        sims = cos_scores.cpu().numpy()

        df["ìœ ì‚¬ë„"] = sims
        df_sorted = df.sort_values(by="ìœ ì‚¬ë„", ascending=False)
        st.write(f"ğŸ” ì¶”ì²œ ê²°ê³¼ ìƒìœ„ {min(5, len(df_sorted))}ê±´")
        for _, row in df_sorted.head(5).iterrows():
            st.markdown(f"### {row['ì‘í’ˆëª…']} â€” {row['ì €ì']}")
            st.write(f"- ì¥ë¥´: {row['ì¥ë¥´']} | ê°ì •: {row['ê°ì •']}")
            st.write(f"- í‰ê°€: {row['í‰ê°€']}")
            st.write(f"- **ìœ ì‚¬ë„**: {row['ìœ ì‚¬ë„']:.3f}")
            st.markdown("---")
