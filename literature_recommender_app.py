import streamlit as st
import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# ---- êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ---- #
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_dict(
    st.secrets["gcp_service_account"], scope
)
client = gspread.authorize(creds)
sheet = client.open("ap jeongbo alzar takkarsenn").sheet1

# ---- Streamlit ì›¹ì•± UI ---- #
st.set_page_config(page_title="ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì…ë ¥", page_icon="ğŸ“š", layout="wide")

st.markdown("""
<style>
    .main {
        background-color: #f9f9f9;
    }
    .stButton>button {
        color: white;
        background-color: #6c63ff;
        border-radius: 0.5rem;
        padding: 0.5rem 1rem;
        border: none;
    }
    .stTextInput>div>input, .stTextArea>div>textarea {
        background-color: #ffffff;
        border-radius: 0.5rem;
        padding: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“š ì‚¬ìš©ì ì°¸ì—¬í˜• ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì¨-ë¹„ì“° : ì•Œìë¥´ íƒ€ì¹´ë¥´ì„¼(alzar takkarrsen)")
st.markdown("""
ì´ í”Œë«í¼ì€ ë‹¤ì–‘í•œ ì‚¬ìš©ìê°€ ì§ì ‘ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œí•˜ê³ , ê·¸ ì¶”ì²œ ì´ìœ ì™€ ê°ì •ì„ í•¨ê»˜ ê¸°ë¡í•¨ìœ¼ë¡œì¨ ì§‘ë‹¨ ì§€ì„± ê¸°ë°˜ì˜ ë¬¸í•™ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•œ ë’¤, AIë¥¼ í†µí•´ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.
""")

st.header("âœï¸ ë…ì„œ ê¸°ë¡ ì…ë ¥ í‹€")
with st.form("book_form"):
    col1, col2 = st.columns(2)
    with col1:
        title = st.text_input("ì‘í’ˆëª…*")
        author = st.text_input("ì €ì*")
        country = st.text_input("êµ­ê°€")
        period = st.text_input("ì‹œëŒ€")
    with col2:
        genre = st.text_input("ì¥ë¥´* (ì˜ˆ: ì†Œì„¤, ì‹œ, í¬ê³¡, ì‚°ë¬¸ ë“±)")
        emotion = st.text_input("ê°ì •* (ì˜ˆ: ê³ ë…, í¬ë§, ìŠ¬í”” ë“± â€” ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°ì • ì…ë ¥ ê°€ëŠ¥)")
        user = st.text_input("ë‹‰ë„¤ì„ (ì„ íƒ)")

    opinion = st.text_area("í‰ê°€*", height=150)
    submit = st.form_submit_button("ğŸ“¤ ë…ì„œ ê¸°ë¡ ì œì¶œ")

    if submit:
        if title and author and opinion:
            row = [title, author, country, period, genre, emotion, opinion, user]
            try:
                sheet.append_row(row)
                st.success("âœ… ë…ì„œ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("âš ï¸ ì‘í’ˆëª…, ì €ì, í‰ê°€ëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.")

# ---- ìµœê·¼ ì¶”ì²œ ì‘í’ˆ ë³´ê¸° ---- #
st.header("ğŸ“„ ìµœê·¼ ì…ë ¥ëœ ì‘í’ˆ")
try:
    data = sheet.get_all_records()
    df_recent = pd.DataFrame(data)
    if not df_recent.empty:
        st.dataframe(df_recent[::-1], use_container_width=True)
    else:
        st.info("ì•„ì§ ì…ë ¥ëœ ì‘í’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
except:
    st.error("Google Sheets ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ë˜ëŠ” ì‹œíŠ¸ ê³µìœ  ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

# ---- ë¬¸í•™ ì‘í’ˆ AI ì¶”ì²œ ---- #
st.header("ğŸ” ë¬¸í•™ ì‘í’ˆ AI ì¶”ì²œ ë°›ê¸°")

@st.cache_data(ttl=600)
def load_data():
    data = sheet.get_all_records()
    df = pd.DataFrame(data)
    if df.empty:
        return pd.DataFrame()
    df.columns = [str(c).strip() for c in df.columns]
    df.fillna("", inplace=True)
    df["ê°ì •"] = df["ê°ì •"].astype(str).str.replace(",", " ")
    df["combined_text"] = ("ì¥ë¥´: " + df["ì¥ë¥´"] + " ê°ì •: " + df["ê°ì •"] + " í‰ê°€: " + df["í‰ê°€"])

@st.cache_resource
def load_model():
    return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

df = load_data()
model = load_model()

query = st.text_input("ì¶”ì²œë°›ê³  ì‹¶ì€ í‚¤ì›Œë“œë‚˜ ê°ì •ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°œ ì…ë ¥ ê°€ëŠ¥)")

if query:
    if df is not None and isinstance(df, pd.DataFrame) and not df.empty:
        query_list = [q.strip() for q in query.split(",")]
        query_emb = model.encode(query_list)
        avg_query_emb = query_emb.mean(axis=0).reshape(1, -1)
        doc_embs = model.encode(df["combined_text"].tolist())
        sims = cosine_similarity(avg_query_emb, doc_embs)[0]
        df["ìœ ì‚¬ë„"] = sims
        top_n = 5
        results = df.sort_values(by="ìœ ì‚¬ë„", ascending=False).head(top_n)

        st.write(f"ğŸ” ì•Œìë¥´ íƒ€ì¹´ë¥´ì„¼ì˜ ì¶”ì²œ ì‘í’ˆ {top_n}ê±´:")
        for _, row in results.iterrows():
            st.markdown(f"### {row['ì‘í’ˆëª…']} - {row['ì €ì']}")
            st.write(f"- **ì¥ë¥´**: {row['ì¥ë¥´']}  |  **ê°ì •**: {row['ê°ì •']}")
            st.write(f"- **í‰ê°€**: {row['í‰ê°€']}")
            st.write(f"- **ìœ ì‚¬ë„ ì ìˆ˜**: {row['ìœ ì‚¬ë„']:.3f}")
            st.markdown("---")
    else:
        st.warning("âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ì¶”ì²œì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘í’ˆì„ í•œ ê°œ ì´ìƒ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")

