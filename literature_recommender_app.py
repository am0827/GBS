import streamlit as st
import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from transformers import pipeline
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity


# êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_dict(
   st.secrets["gcp_service_account"], scope
)
client = gspread.authorize(creds)
sheet = client.open("ap jeongbo alzar takkarsenn").sheet1




# Streamlit ì›¹ì•± UI
st.set_page_config(page_title="ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì…ë ¥", page_icon="ğŸ“š", layout="wide")


st.markdown("""
<style>
   .main {
       background-color: #f9f9f9;
   }
   .stButton>button {
       color: white;
       background-color: #6c63ff;
       border-radius: 0.5rem;
       padding: 0.5rem 1rem;
       border: none;
   }
   .stTextInput>div>input, .stTextArea>div>textarea {
       background-color: #ffffff;
       border-radius: 0.5rem;
       padding: 0.5rem;
   }
</style>
""", unsafe_allow_html=True)


st.title("ğŸ“š ì‚¬ìš©ì ì°¸ì—¬í˜• ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì¨-ë¹„ì“° : ì•Œìë¥´ íƒì¹´ë¥´ì„¼(alzar takkarsenn)")
st.markdown("""
ì´ í”Œë«í¼ì€ ë‹¤ì–‘í•œ ì‚¬ìš©ìê°€ ì§ì ‘ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œí•˜ê³ , ê·¸ ì¶”ì²œ ì´ìœ ì™€ ê°ì •ì„ í•¨ê»˜ ê¸°ë¡í•¨ìœ¼ë¡œì¨ ì§‘ë‹¨ ì§€ì„± ê¸°ë°˜ì˜ ë¬¸í•™ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•œ ë’¤, AIë¥¼ í†µí•´ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.
""")


st.header("âœï¸ ë…ì„œ ê¸°ë¡ ì…ë ¥ í‹€")
with st.form("book_form"):
    col1, col2 = st.columns(2)
    with col1:
        title = st.text_input("ì‘í’ˆëª…*")
        author = st.text_input("ì €ì*")
        country = st.text_input("êµ­ê°€")
        period = st.text_input("ì‹œëŒ€")
    with col2:
        genre = st.text_input("ì¥ë¥´* (ì˜ˆ: ì†Œì„¤, ì‹œ, í¬ê³¡, ì‚°ë¬¸ ë“±)")
        emotion = st.text_input("ê°ì •* (ì˜ˆ: ê³ ë…, í¬ë§, ìŠ¬í”” ë“± â€” ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°ì • ì…ë ¥ ê°€ëŠ¥)")
        user = st.text_input("ë‹‰ë„¤ì„ (ì„ íƒ)")

    reason = st.text_area("ì¶”ì²œ ì´ìœ *", height=150)
    submit = st.form_submit_button("ğŸ“¤ ë…ì„œ ê¸°ë¡ ì œì¶œ")

    if submit:
        if title and author and reason:
            row = [title, author, country, period, genre, emotion, reason, user]
            try:
                sheet.append_row(row)
                st.success("âœ… ë…ì„œ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("âš ï¸ ì‘í’ˆëª…, ì €ì, ì¶”ì²œ ì´ìœ ëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.")



# ìµœê·¼ ì…ë ¥ ì‘í’ˆ ë³´ê¸°
st.header("ğŸ“„ ìµœê·¼ ì…ë ¥ëœ ì‘í’ˆ")
try:
   data = sheet.get_all_records()
   if data:
       df = pd.DataFrame(data)
       st.dataframe(df[::-1], use_container_width=True)
   else:
       st.info("ì•„ì§ ì…ë ¥ëœ ì‘í’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
except:
   st.error("Google Sheets ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ë˜ëŠ” ì‹œíŠ¸ ê³µìœ  ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")






st.header("ğŸ”ì•Œìë¥´ íƒì¹´ë¥´ì„¼ì—ê²Œ ë„ì„œ ì¶”ì²œë°›ê¸°")


@st.cache_data(ttl=600)
def load_data():
    data = sheet.get_all_records()
    df = pd.DataFrame(data)
    if df.empty:
        return pd.DataFrame()
    df.columns = [str(c).strip() for c in df.columns]
    df.fillna("", inplace=True)
    df["ê°ì •"] = df["ê°ì •"].astype(str).str.replace(",", " ")
    df["combined_text"] = df["ì¶”ì²œ ì´ìœ "] + " " + df["ê°ì •"] + " " + df["ì¥ë¥´"]
    return df


@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

df = load_data()
model = load_model()


query = st.text_input("ì¶”ì²œë°›ê³  ì‹¶ì€ í‚¤ì›Œë“œë‚˜ ê°ì •ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°œ ì…ë ¥ ê°€ëŠ¥)")

if query and not df.empty:
    query_list = [q.strip() for q in query.split(",")]
    query_emb = model.encode(query_list)
    avg_query_emb = query_emb.mean(axis=0).reshape(1, -1)
    doc_embs = model.encode(df["combined_text"].tolist())
    sims = cosine_similarity(avg_query_emb, doc_embs)[0]
    df["ìœ ì‚¬ë„"] = sims
    top_n = 5
    results = df.sort_values(by="ìœ ì‚¬ë„", ascending=False).head(top_n)


st.write(f"ğŸ” ì•Œìë¥´ íƒ€ì¹´ë¥´ì„¼ì˜ ì¶”ì²œ ì‘í’ˆ {top_n}ê±´:")
    for _, row in results.iterrows():
        st.markdown(f"### {row['ì‘í’ˆëª…']} - {row['ì €ì']}")
        st.write(f"- **ì¥ë¥´**: {row['ì¥ë¥´']}  |  **ê°ì •**: {row['ê°ì •']}")
        st.write(f"- **ì¶”ì²œ ì´ìœ **: {row['ì¶”ì²œ ì´ìœ ']}")
        st.write(f"- **ìœ ì‚¬ë„ ì ìˆ˜**: {row['ìœ ì‚¬ë„']:.3f}")
        st.markdown("---")

elif query:
    st.warning("âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ì¶”ì²œì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘í’ˆì„ í•œ ê°œ ì´ìƒ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
