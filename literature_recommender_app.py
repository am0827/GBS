import streamlit as st
import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from sentence_transformers import SentenceTransformer, util
import torch

# ---- êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ---- #
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_dict(
    st.secrets["gcp_service_account"], scope
)
client = gspread.authorize(creds)
sheet = client.open("ap jeongbo alzar takkarsenn").sheet1

# ---- Streamlit ì›¹ì•± UI ---- #
st.set_page_config(page_title="ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì…ë ¥", page_icon="ğŸ“š", layout="wide")

st.markdown("""
<style>
    .main {
        background-color: #f9f9f9;
    }
    .stButton>button {
        color: white;
        background-color: #6c63ff;
        border-radius: 0.5rem;
        padding: 0.5rem 1rem;
        border: none;
    }
    .stTextInput>div>input, .stTextArea>div>textarea {
        background-color: #ffffff;
        border-radius: 0.5rem;
        padding: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“š ì‚¬ìš©ì ì°¸ì—¬í˜• ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì¨-ë¹„ìŠ¤ : ì•Œìë¥´ íƒ€ì¹´ë¥´ì„¼(alzar takkarrsen)")
st.markdown("""
ì´ í”Œë«í¼ì€ ë‹¤ì–‘í•œ ì‚¬ìš©ìê°€ ì§€ì  ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œí•˜ê³ , ê·¸ ì¶”ì²œ ì´ìœ ì™€ ê°ì •ì„ í•¨ê»˜ ê¸°ë¡í•¨ìœ¼ë¡œì¨ ì§‘ë‹¨ ì§€ì„± ê¸°ë°˜ì˜ ë¬¸í•™ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•œ ë’¤, AIë¥¼ í†µí•´ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.
""")

st.header("âœï¸ ë…ì„œ ê¸°ë¡ ì…ë ¥ íë¦„")
with st.form("book_form"):
    col1, col2 = st.columns(2)
    with col1:
        title = st.text_input("ì‘í’ˆëª…*")
        author = st.text_input("ì €ì*")
        country = st.text_input("êµ­ê°€")
        period = st.text_input("ì‹œëŒ€")
    with col2:
        genre = st.text_input("ì¥ë¥´* (ì˜ˆ: ì†Œì„¤, ì‹œ, í¬ê³¡, ì‚°ë¬¸ ë“±)")
        emotion = st.text_input("ê°ì •* (ì˜ˆ: ê³ ë…, í¬ë§, ìŠ¬í”” ë“± â€” ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°ì • ì…ë ¥ ê°€ëŠ¥)")
        user = st.text_input("ë‹‰ë„¤ì„ (ì„ íƒ)")

    opinion = st.text_area("í‰ê°€*", height=150)
    submit = st.form_submit_button("ğŸ“¤ ë…ì„œ ê¸°ë¡ ì œì¶œ")

    if submit:
        if title and author and opinion:
            row = [title, author, country, period, genre, emotion, opinion, user]
            try:
                sheet.append_row(row)
                st.success("âœ… ë…ì„œ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("âš ï¸ ì‘í’ˆëª…, ì €ì, í‰ê°€ëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.")

# ---- ê²½ê³¼ ë³´ê¸° ---- #
st.header("ğŸ“„ ê²½ê³¼ ë³´ê¸°")
try:
    data = sheet.get_all_records()
    df_recent = pd.DataFrame(data)
    if not df_recent.empty:
        st.dataframe(df_recent[::-1], use_container_width=True)
    else:
        st.info("ì•„ì§ ì…ë ¥ëœ ì‘í’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
except:
    st.error("Google Sheets ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ë ¤ë©´ API í‚¤ ë˜ëŠ” ì‹œíŠ¸ ê³µìœ  ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ---- AI ì°¸ì¡° ë°›ê¸° ---- #
st.header("ğŸ” ë¬¸í•™ ì‘í’ˆ AI ì°¸ì¡° ë°›ê¸°")

@st.cache_data(ttl=600)
def load_data():
    data = sheet.get_all_records()
    df = pd.DataFrame(data)
    if df.empty:
        return pd.DataFrame()
    df.columns = [str(c).strip() for c in df.columns]
    df.fillna("", inplace=True)
    # ì‰¼í‘œëŠ” ê³µë°±ìœ¼ë¡œ ë³€ê²½ (í‚¤ì›Œë“œ ë§¤ì¹­ ìš©ì´)
    df["ê°ì •"] = df["ê°ì •"].astype(str).str.replace(",", " ")
    df["combined_text"] = ("ì¥ë¥´: " + df["ì¥ë¥´"] + " ê°ì •: " + df["ê°ì •"] + " í‰ê°€: " + df["í‰ê°€"])
    return df

@st.cache_resource
def load_model():
    return SentenceTransformer("jhgan/ko-sroberta-multitask")

df = load_data()
model = load_model()

query = st.text_input("ì¶”ì²œë°›ê³  ì‹¶ì€ í‚¤ì›Œë“œë‚˜ ê°ì •ì„ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°œ ì…ë ¥ ê°€ëŠ¥)")

if query:
    if df is not None and isinstance(df, pd.DataFrame) and not df.empty:
        query_list = [q.strip() for q in query.split(",")]

        # query ë¬¸ì¥ ì„ë² ë”© (tensor)
        query_embs = model.encode(query_list, convert_to_tensor=True)
        # í‰ê·  ë²¡í„° (tensor)
        avg_query_emb = torch.mean(query_embs, dim=0, keepdim=True)

        # ë¬¸ì„œ ì„ë² ë”© (tensor)
        doc_embs = model.encode(df["combined_text"].tolist(), convert_to_tensor=True)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (tensor)
        cos_scores = util.pytorch_cos_sim(avg_query_emb, doc_embs)[0]

        # numpy ë°°ì—´ë¡œ ë³€í™˜
        sims = cos_scores.cpu().numpy()

        df["ìœ ì‚¬ë„"] = sims

        # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (ê°ì •, ì¥ë¥´, í‰ê°€ ëª¨ë‘ ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ í™•ì¸)
        df["í‚¤ì›Œë“œì ìˆ˜"] = 0
        for kw in query_list:
            df["í‚¤ì›Œë“œì ìˆ˜"] += df["ê°ì •"].str.contains(kw, case=False, na=False) * 1.0
            df["í‚¤ì›Œë“œì ìˆ˜"] += df["ì¥ë¥´"].str.contains(kw, case=False, na=False) * 1.0
            df["í‚¤ì›Œë“œì ìˆ˜"] += df["í‰ê°€"].str.contains(kw, case=False, na=False) * 1.0

        # ìµœì¢… ì ìˆ˜ ê³„ì‚°: ìœ ì‚¬ë„ ë°˜ì˜ ë¹„ìœ¨ 0.7, í‚¤ì›Œë“œ ë°˜ì˜ ë¹„ìœ¨ 0.3
        df["ìµœì¢…ì ìˆ˜"] = df["ìœ ì‚¬ë„"] * 0.7 + df["í‚¤ì›Œë“œì ìˆ˜"] * 0.3

        df_sorted = df.sort_values(by="ìµœì¢…ì ìˆ˜", ascending=False)

        top_n = min(5, len(df_sorted))
        st.write(f"ğŸ” ì•Œìë¥´ íƒ€ì¹´ë¥´ì„¼ì˜ ì¶”ì²œ ì‘í’ˆ {top_n}ê±´:")

        for _, row in df_sorted.head(top_n).iterrows():
            st.markdown(f"### {row['ì‘í’ˆëª…']} - {row['ì €ì']}")
            st.write(f"- **ì¥ë¥´**: {row['ì¥ë¥´']}  |  **ê°ì •**: {row['ê°ì •']}")
            st.write(f"- **í‰ê°€**: {row['í‰ê°€']}")
            st.write(f"- **ìœ ì‚¬ë„**: {row['ìœ ì‚¬ë„']:.3f} | **í‚¤ì›Œë“œì ìˆ˜**: {row['í‚¤ì›Œë“œì ìˆ˜']:.2f} | **ìµœì¢…ì ìˆ˜**: {row['ìµœì¢…ì ìˆ˜']:.3f}")
            st.markdown("---")
    else:
        st.warning("âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ì¶”ì²œì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘í’ˆì„ í•œ ê°œ ì´ìƒ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
