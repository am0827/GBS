import streamlit as st
import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials
from transformers import pipeline
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# ---- êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ---- #
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name("ap-jeongbo-00cfcfa3b3ce.json", scope)
client = gspread.authorize(creds)
sheet = client.open("ap jeongbo alzar takarrsen").sheet1  # ì‹œíŠ¸ ì´ë¦„ì— ë§ê²Œ ìˆ˜ì •

# ---- Streamlit ì›¹ì•± UI ---- #
st.set_page_config(page_title="ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì…ë ¥", page_icon="ğŸ“š", layout="wide")

st.markdown("""
<style>
    .main {
        background-color: #f9f9f9;
    }
    .stButton>button {
        color: white;
        background-color: #6c63ff;
        border-radius: 0.5rem;
        padding: 0.5rem 1rem;
        border: none;
    }
    .stTextInput>div>input, .stTextArea>div>textarea {
        background-color: #ffffff;
        border-radius: 0.5rem;
        padding: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“š ì‚¬ìš©ì ì°¸ì—¬í˜• ë¬¸í•™ ì‘í’ˆ ì¶”ì²œ ì¨-ë¹„ì“° : ì•Œìë¥´ íƒ€ì¹´ë¥´ì„¼(alzar takarrsen)")
st.markdown("""
ì´ í”Œë«í¼ì€ ë‹¤ì–‘í•œ ì‚¬ìš©ìê°€ ì§ì ‘ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œí•˜ê³ , ê·¸ ì¶”ì²œ ì´ìœ ì™€ ê°ì •ì„ í•¨ê»˜ ê¸°ë¡í•¨ìœ¼ë¡œì¨ ì§‘ë‹¨ ì§€ì„± ê¸°ë°˜ì˜ ë¬¸í•™ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•œ ë’¤, AIë¥¼ í†µí•´ ë¬¸í•™ ì‘í’ˆì„ ì¶”ì²œë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤.
""")

st.header("âœï¸ ë…ì„œ ê¸°ë¡ ì…ë ¥ í‹€")
with st.form("book_form"):
    col1, col2 = st.columns(2)
    with col1:
        title = st.text_input("ì‘í’ˆëª…*")
        author = st.text_input("ì €ì*")
        country = st.text_input("êµ­ê°€")
        period = st.text_input("ì‹œëŒ€")
    with col2:
        genre = st.text_input("ì¥ë¥´* (ì˜ˆ: ì†Œì„¤, ì‹œ, í¬ê³¡, ì‚°ë¬¸ ë“±)")
        emotion = st.text_input("ê°ì •* (ì˜ˆ: ê³ ë…, í¬ë§, ìŠ¬í”” ë“±)")
        user = st.text_input("ë‹‰ë„¤ì„ (ì„ íƒ)")

    reason = st.text_area("ì¶”ì²œ ì´ìœ *", height=150)
    submit = st.form_submit_button("ğŸ“¤ ë…ì„œ ê¸°ë¡ ì œì¶œ")

    if submit:
        if title and author and reason:
            row = [title, author, country, period, genre, emotion, reason, user]
            try:
                sheet.append_row(row)
                st.success("âœ… ë…ì„œ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("âš ï¸ ì‘í’ˆëª…, ì €ì, ì¶”ì²œ ì´ìœ ëŠ” í•„ìˆ˜ ì…ë ¥ í•­ëª©ì…ë‹ˆë‹¤.")

# ---- ìµœê·¼ ì¶”ì²œ ì‘í’ˆ ë³´ê¸° ---- #
st.header("ğŸ“„ ìµœê·¼ ì¶”ì²œëœ ì‘í’ˆ")
try:
    data = sheet.get_all_records()
    if data:
        df = pd.DataFrame(data)
        st.dataframe(df[::-1], use_container_width=True)
    else:
        st.info("ì•„ì§ ì¶”ì²œëœ ì‘í’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
except:
    st.error("Google Sheets ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ë˜ëŠ” ì‹œíŠ¸ ê³µìœ  ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")



st.header("ğŸ” ë¬¸í•™ ì‘í’ˆ AI ì¶”ì²œ ë°›ê¸°")

@st.cache_data(ttl=600)
def load_data():
    try:
        data = sheet.get_all_records()
        if not data:
            st.warning("ğŸ“­ ì•„ì§ ë°ì´í„°ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.stop()
        df = pd.DataFrame(data)
        df.columns = [str(col).strip() for col in df.columns]
        df.fillna("", inplace=True)
        st.write("ğŸ“Œ í˜„ì¬ DataFrame ì»¬ëŸ¼ëª… ëª©ë¡:", df.columns.tolist())
        df["combined_text"] = df["ì¶”ì²œ ì´ìœ "] + " " + df["ê°ì •"] + " " + df["ì¥ë¥´"]
        return df
    except Exception as e:
        st.error(f"âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜

@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

df = load_data()
model = load_model()

query = st.text_input("ì¶”ì²œë°›ê³  ì‹¶ì€ í‚¤ì›Œë“œë‚˜ ê°ì •ì„ ì…ë ¥í•˜ì„¸ìš”")

if query:
    query_emb = model.encode([query])
    doc_embs = model.encode(df["combined_text"].tolist())
    sims = cosine_similarity(query_emb, doc_embs)[0]
    df["ìœ ì‚¬ë„"] = sims
    top_n = 5
    results = df.sort_values(by="ìœ ì‚¬ë„", ascending=False).head(top_n)

    st.write(f"ğŸ” '{query}'ì™€ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì¶”ì²œ ì‘í’ˆ {top_n}ê±´:")
    for _, row in results.iterrows():
        st.markdown(f"### {row['ì‘í’ˆëª…']} - {row['ì €ì']}")
        st.write(f"- **ì¥ë¥´**: {row['ì¥ë¥´']}  |  **ê°ì •**: {row['ê°ì •']}")
        st.write(f"- **ì¶”ì²œ ì´ìœ **: {row['ì¶”ì²œ ì´ìœ ']}")
        st.write(f"- **ìœ ì‚¬ë„ ì ìˆ˜**: {row['ìœ ì‚¬ë„']:.3f}")
        st.markdown("---")

